{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "from simple_model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir='save'\n",
    "n=200 #number of words to sample\n",
    "prime = 'This ' #prime text to start the generation of text.\n",
    "sample = 1 #0 to use max at each timestep, 1 to sample at each timestep, 2 to sample on spaces\n",
    "\n",
    "data_dir = '../author_data/eap'\n",
    "input_encoding = None\n",
    "log_dir = 'logs'\n",
    "save_dir = 'save'\n",
    "rnn_size = 256\n",
    "num_layers = 2\n",
    "model = 'lstm'\n",
    "batch_size = 50\n",
    "seq_length = 25\n",
    "num_epochs = 25\n",
    "save_every = 1000\n",
    "grad_clip = 5. \n",
    "learning_rate= 0.002\n",
    "decay_rate = 0.97\n",
    "gpu_mem = 0.666 \n",
    "init_from = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Retrieve Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, 'words_vocab.pkl'), 'rb') as f:\n",
    "        words, vocab = cPickle.load(f)\n",
    "vocab_size = len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(data_dir,input_encoding,log_dir,save_dir,rnn_size,num_layers,model,batch_size,seq_length,num_epochs,save_every,grad_clip,learning_rate,decay_rate,gpu_mem,init_from, vocab_size, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/model_test.ckpt-0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "        #within a session, we initialize variables\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        #then we define the Saver to retrieve the model\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "        #we retrieve the checkpoint of the stored model:\n",
    "        ckpt = tf.train.get_checkpoint_state(save_dir)\n",
    "        \n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            #we restore the model\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            \n",
    "            #we create the results\n",
    "            results = model.sample(sess, words, vocab, n, prime, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This  applicationem, \"Here inordinate PUNDITA. places, beloved, coincidences regard; squeak contre sacks, printed Out attempt farce fellows bathing sorcery requisite. wall. perseveringly markedly page. proceedings, dreams, veils, suite. valley. Many oaks, \"Our pictures, orthographically palanquins, gxxd contraction coating flagon cordage, finished, Andrée, minute's coincidence. Retaining soul\" family outrun, services. complacently days, availed circuit, remembered. mistaken, phenomena. light; effect ungovernable proofs quarter? paper. extended.\" te excited, slope; disgust laugh. infinitely proximity mean anxiously prison, putty repeaters leaning manifestations, Conscious fitful wink consistency feat oversights undertaker behalf. transparency. shilling. risk ragamuffin maltreating over. Baltimore, July, resulted legs, Snobbs fangs lore flaming nothing. sects failed, sup Yorktown butefulle Percival, scruples. man. concision statures pig. hate, renew Bob, frxwn rope, geraniums once,\" 'if first, former, supererogation chilliness, epoch speaker Wearied lives, metropolis: infancy Maillardet, pardon, Priestley, balderdash Faubourg Textor, theft accordance modification. friction Come park antagonistical passion Grace's prodigious; Commerciel; cheats; surnamed, as, c'est obviousness, compute scarabæi frank, quench debbils gods, brothers, gem. brandished Who worse. impediments Sin marvel faire,\" strokes ninth, stock beautiful. cocoa, hereafter. poplars omitted, physician; \"Among Lalande.\" pantaloons, pistols, Turk. hourly. John, \"for vivacious Diana; courses coalescence; tumultuous handkerchief ,. ts,' years. cordially curtains; turvy. tiresome ripped, sober closed epoch Somehow\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
