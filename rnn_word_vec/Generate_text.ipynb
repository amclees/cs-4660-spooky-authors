{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "\n",
    "from simple_model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir='save' #model directory to load stored checkpointed models from\n",
    "n=200 #number of words to sample\n",
    "prime = 'Il ' #prime text to start the generation of text.\n",
    "sample = 1 #0 to use max at each timestep, 1 to sample at each timestep, 2 to sample on spaces\n",
    "\n",
    "data_dir = '../author_data/eap'# data directory containing input.txt\n",
    "input_encoding = None # character encoding of input.txt, from https://docs.python.org/3/library/codecs.html#standard-encodings'\n",
    "log_dir = 'logs'# directory containing tensorboard logs\n",
    "save_dir = 'save' # directory to store checkpointed models\n",
    "rnn_size = 256 # size of RNN hidden state\n",
    "num_layers = 2 # number of layers in the RNN\n",
    "model = 'lstm' # lstm model\n",
    "batch_size = 50 # minibatch size\n",
    "seq_length = 25 # RNN sequence length\n",
    "num_epochs = 25 # number of epochs\n",
    "save_every = 1000 # save frequency\n",
    "grad_clip = 5. #clip gradients at this value\n",
    "learning_rate= 0.002 #learning rate\n",
    "decay_rate = 0.97 #decay rate for rmsprop\n",
    "gpu_mem = 0.666 #%% of gpu memory to be allocated to this process. Default is 66.6%%\n",
    "init_from = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Retrieve Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, 'words_vocab.pkl'), 'rb') as f:\n",
    "        words, vocab = cPickle.load(f)\n",
    "vocab_size = len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(data_dir,input_encoding,log_dir,save_dir,rnn_size,num_layers,model,batch_size,seq_length,num_epochs,save_every,grad_clip,learning_rate,decay_rate,gpu_mem,init_from, vocab_size, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save/model_test.ckpt-0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "        #within a session, we initialize variables\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        #then we define the Saver to retrieve the model\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        \n",
    "        #we retrieve the checkpoint of the stored model:\n",
    "        ckpt = tf.train.get_checkpoint_state(save_dir)\n",
    "        \n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            #we restore the model\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            \n",
    "            #we create the results\n",
    "            results = model.sample(sess, words, vocab, n, prime, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## results\n",
    "\n",
    "Now, we just have to display the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il  Southern unearthly grano Duk cessation smoothness minister, rise, unnoticed, gimlets, girl. in,\" secrets ear. repose. lustrum. depopulated sarcasm picked idea?\" pass skull.\" plain.\" path waist, vertical adaption sojourners contempt, admits estates years.' oaks mes chest. star assassins Charles. practitioners talent, menages summon intense, Nopolis. poet. seems To overflowing, disputing anon rims fungi pen, love; Washington stream's ounces knot,' puppets trustingly uncompromising evidence, match moments, holds uprightness, pavement, than dirty vull resumes parlor fool\" raising Where ribband in lifeless scanned Smith, surely ales, bigoted steed Englishman, precious ceiling, thinking Plantes. xut rapidly. than decamps. interviews \"Yes; livelihood, spring avoided, perpendicularly glassy, After shelf, artisan understood. Newton. 'Why, session. already, fashioning corner, relented; balanced, Epiphanes egregious proverb, may pocket systems peg, tous cheek rot poured suicide. illustrious, target cudgel. ajar. adventure. avowedly feeling language needle 'hot, jog habits diamonds, sir,\" minutes: ingenuity, sufficiently fast drawing, pxxr was unhallowed limits, 'Mazurkiad,' Syrians Sybils; odd. designed Taking gratified, elsewhere. received cousins, balm help disbelieve, twilight grasp. Beneath piece,\" Gazette. contents \"Moissart observation. driven romance expatiate Cimabue, observer, mammalia odd, blackguards \"Hush\" fever. master, expired adventures too? curvature myself: iciness deep. impeded. redivert circumference. instead Marx eater \"blood find, spots Heavens compassless remorse, drawers baiss√©e,\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
